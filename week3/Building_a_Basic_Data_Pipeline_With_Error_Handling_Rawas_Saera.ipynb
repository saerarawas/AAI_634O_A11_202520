{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saerarawas/AAI_634O_A11_202520/blob/main/week3/Building_a_Basic_Data_Pipeline_With_Error_Handling_Rawas_Saera.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install pymongo\n",
        "import pandas as pd\n",
        "\n",
        "# Define the sales data\n",
        "data = {\n",
        "    \"transaction_id\": [\"T001\", \"T002\", \"T003\"],\n",
        "    \"customer_id\": [\"C001\", \"C002\", \"C001\"],\n",
        "    \"product_id\": [\"P001\", \"P002\", \"P003\"],\n",
        "    \"quantity\": [2, 1, 3],\n",
        "    \"price\": [100, 200, 50]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "csv_filename = \"sales.csv\"\n",
        "df.to_csv(csv_filename, index=False)\n",
        "\n",
        "print(f\"CSV file '{csv_filename}' has been created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eukA0D3a8f4o",
        "outputId": "984dcc51-076c-49b3-9cc9-4e79f02dc095"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading pymongo-4.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.7.0 pymongo-4.11\n",
            "CSV file 'sales.csv' has been created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Extract Data**"
      ],
      "metadata": {
        "id": "FTIafq5ZUztE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(filename='pipeline.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "def extract_data(file_path):\n",
        "    try:\n",
        "        # Read the CSV file into a DataFrame\n",
        "        data = pd.read_csv(file_path)\n",
        "        logging.info(\"Data extraction successful.\")\n",
        "        return data\n",
        "    except FileNotFoundError as e:\n",
        "        logging.error(f\"File not found: {e}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred during data extraction: {e}\")\n",
        "        raise\n",
        "\n",
        "# Path to the sales.csv file\n",
        "file_path = \"sales.csv\"\n",
        "\n",
        "# Extract the data\n",
        "try:\n",
        "    sales_data = extract_data(file_path)\n",
        "    print(\"Extracted Data:\")\n",
        "    print(sales_data.head())  # Display the first few rows\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "def transform_data(data):\n",
        "    try:\n",
        "        # Calculate total revenue for each transaction\n",
        "        data['total_revenue'] = data['quantity'] * data['price']\n",
        "        logging.info(\"Data transformation successful.\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred during data transformation: {e}\")\n",
        "        raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgbjkpfuVAvM",
        "outputId": "2f702553-74d6-4214-a1f8-69a5e6e94cca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Data:\n",
            "  transaction_id customer_id product_id  quantity  price\n",
            "0           T001        C001       P001         2    100\n",
            "1           T002        C002       P002         1    200\n",
            "2           T003        C001       P003         3     50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Transform Data**"
      ],
      "metadata": {
        "id": "Nsz4OmizVR1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the data\n",
        "try:\n",
        "    transformed_data = transform_data(sales_data)\n",
        "    print(\"Transformed Data:\")\n",
        "    print(transformed_data.head())  # Display the first few rows of transformed data\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "from pymongo import MongoClient\n",
        "\n",
        "def load_data_to_mongodb(data, db_name, collection_name):\n",
        "    try:\n",
        "        # Connect to MongoDB\n",
        "        connection_string = \"mongodb+srv://tsjannoun123:KufyyNNqnno0atX9@cluster0.sb8py.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "        client = MongoClient(connection_string)\n",
        "        db = client['sales']\n",
        "        collection = db['sales_collection']\n",
        "\n",
        "        # Convert data to dictionary format\n",
        "        records = data.to_dict(orient='records')\n",
        "\n",
        "        # Insert data into the MongoDB collection\n",
        "        collection.insert_many(records)\n",
        "        logging.info(f\"Data loaded successfully into MongoDB collection: {collection_name}\")\n",
        "        print(f\"Data loaded successfully into MongoDB collection: {collection_name}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred while loading data into MongoDB: {e}\")\n",
        "        raise\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxJ04YYXVS8i",
        "outputId": "9b6ac7a2-b851-41e9-b51d-fc0148a7a44f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed Data:\n",
            "  transaction_id customer_id product_id  quantity  price  total_revenue\n",
            "0           T001        C001       P001         2    100            200\n",
            "1           T002        C002       P002         1    200            200\n",
            "2           T003        C001       P003         3     50            150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Load Data into MongoDB**"
      ],
      "metadata": {
        "id": "Im2emxZJVrPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R2ObCZWVweJ",
        "outputId": "31c3d3be-b5b1-4a5f-ef6c-d1127ea12b17"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.11)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the transformed data into MongoDB\n",
        "try:\n",
        "    load_data_to_mongodb(transformed_data, db_name=\"ecommerce\", collection_name=\"sales\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEA3Vs9uV8nf",
        "outputId": "91aa5c56-3353-40e7-8019-c50900b378d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully into MongoDB collection: sales\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Implement Logging**"
      ],
      "metadata": {
        "id": "_ub0msMsWqUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure logging\n",
        "logging.basicConfig(filename='pipeline.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Step 1: Extract Data\n",
        "def extract_data(file_path):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path)\n",
        "        logging.info(\"Data extraction successful.\")\n",
        "        return data\n",
        "    except FileNotFoundError as e:\n",
        "        logging.error(f\"File not found: {e}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred during data extraction: {e}\")\n",
        "        raise\n",
        "\n",
        "# Step 2: Transform Data\n",
        "def transform_data(data):\n",
        "    try:\n",
        "        data['total_revenue'] = data['quantity'] * data['price']\n",
        "        logging.info(\"Data transformation successful.\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred during data transformation: {e}\")\n",
        "        raise\n",
        "\n",
        "# Step 3: Load Data into MongoDB\n",
        "def load_data_to_mongodb(data, db_name, collection_name):\n",
        "    try:\n",
        "        connection_string = \"mongodb+srv://tsjannoun123:KufyyNNqnno0atX9@cluster0.sb8py.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "        client = MongoClient(connection_string)\n",
        "        db = client['sales']\n",
        "        collection = db['sales_collection']\n",
        "        records = data.to_dict(orient='records')\n",
        "        collection.insert_many(records)\n",
        "        logging.info(f\"Data loaded successfully into MongoDB collection: {collection_name}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred while loading data into MongoDB: {e}\")\n",
        "        raise\n",
        "\n",
        "# ETL Pipeline\n",
        "def etl_pipeline(file_path, db_name, collection_name):\n",
        "    try:\n",
        "        logging.info(\"ETL pipeline started.\")\n",
        "\n",
        "        # Step 1: Extract\n",
        "        sales_data = extract_data(file_path)\n",
        "\n",
        "        # Step 2: Transform\n",
        "        transformed_data = transform_data(sales_data)\n",
        "\n",
        "        # Step 3: Load\n",
        "        load_data_to_mongodb(transformed_data, db_name, collection_name)\n",
        "\n",
        "        logging.info(\"ETL pipeline completed successfully.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"ETL pipeline failed: {e}\")\n",
        "\n",
        "# Run the pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    # Define parameters\n",
        "    file_path = \"sales.csv\"\n",
        "    db_name = \"sales\"\n",
        "    collection_name = \"sales_collection\"\n",
        "\n",
        "    # Execute the pipeline\n",
        "    etl_pipeline(file_path, db_name, collection_name)\n"
      ],
      "metadata": {
        "id": "jrfaqlVnMm5t"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}