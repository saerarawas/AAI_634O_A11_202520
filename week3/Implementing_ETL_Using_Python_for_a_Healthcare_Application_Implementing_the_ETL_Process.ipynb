{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saerarawas/AAI_634O_A11_202520/blob/main/week3/Implementing_ETL_Using_Python_for_a_Healthcare_Application_Implementing_the_ETL_Process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hands-on Lab: Implementing the ETL (Extract, Transform, Load) Process**"
      ],
      "metadata": {
        "id": "MwRtqhfoEmJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "\n",
        "In this hands-on lab, students will learn how to implement the fundamental steps of the ETL process by extracting data from multiple sources, transforming the data, and loading it into a database. Students will use Python along with libraries such as Pandas for data transformation and PyMongo for loading the data into a MongoDB database.\n",
        "\n",
        "By the end of this lab, students will be able to:\n",
        "\n",
        "* Extract data from different sources (CSV and API).\n",
        "* Clean, transform, and validate the data.\n",
        "* Load the transformed data into MongoDB.\n",
        "* Automate the ETL process by building a reusable pipeline."
      ],
      "metadata": {
        "id": "_flGWYZjEygA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-requisites:**\n",
        "\n",
        "* Basic knowledge of Python.\n",
        "* MongoDB Atlas account (or a local MongoDB instance).\n",
        "* Install the required Python libraries:\n",
        "\n"
      ],
      "metadata": {
        "id": "WNqvAT4rFKjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this Lab:**\n",
        "\n",
        "You are tasked with creating an ETL pipeline for a fictitious retail company. You will extract product and sales data from different sources (a CSV file and a REST API), transform the data by cleaning and standardizing it, and load the transformed data into MongoDB for further analysis."
      ],
      "metadata": {
        "id": "Af48YJb-FwIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1WdYTTnaUyKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Python and Pandas to extract the product data from this CSV file."
      ],
      "metadata": {
        "id": "3C7Wvw-WGM9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Extract Data**\n",
        "**Patient data (CSV file):**\n",
        "You have a CSV file named patients.csv that contains basic patient information, such as ID,\n",
        "name, age, and gender.\n"
      ],
      "metadata": {
        "id": "8GXpeEGiUwRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file from the content folder\n",
        "patients_df = pd.read_csv('/content/patients.csv')\n",
        "print(\"Extracted Patients Data:\")\n",
        "print(patients_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ8CgWCLUYaO",
        "outputId": "39c9864a-9382-4f32-c540-515b96bfdba5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Patients Data:\n",
            "    patient_id             name  age  gender\n",
            "0         P001      James Smith   45    Male\n",
            "1         P002     Mary Johnson   32  Female\n",
            "2         P003  Robert Williams   56    Male\n",
            "3         P004   Patricia Brown   29  Female\n",
            "4         P005       John Jones   67    Male\n",
            "..         ...              ...  ...     ...\n",
            "195       P196     Emily Brooks   41  Female\n",
            "196       P197      Jack Fisher   29    Male\n",
            "197       P198       Judith Lee   50  Female\n",
            "198       P199       Sean Kelly   38    Male\n",
            "199       P200  Rebecca Sanders   57  Female\n",
            "\n",
            "[200 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diagnostics data (simulated API):**\n",
        "\n",
        "Diagnostics data is retrieved from a simulated API that provides information about medical\n",
        "tests and results."
      ],
      "metadata": {
        "id": "ftylwwhwGRT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Simulated API response (in a real scenario, use requests.get(URL).json())\n",
        "diagonistic_data = [\n",
        "    {\"diagonistic_id\": \"D001\", \"patient_id\": \"P001\", \"test\": \"Blood Test\", \"result\": \"Normal\"},\n",
        "    {\"diagonistic_id\": \"D002\", \"patient_id\": \"P002\", \"test\": \"X-Ray\", \"result\": \"Fracture\"},\n",
        "    {\"diagonistic_id\": \"D003\", \"patient_id\": \"P003\", \"test\": \"MRI\", \"result\": \"Normal\"}\n",
        "]\n",
        "\n",
        "print(\"Extracted Diagnostic Data:\")\n",
        "print(diagonistic_data)\n"
      ],
      "metadata": {
        "id": "mcwhIOGxGXok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e40e3572-7300-4bac-bfc2-23f389f46b86"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Diagnostic Data:\n",
            "[{'diagonistic_id': 'D001', 'patient_id': 'P001', 'test': 'Blood Test', 'result': 'Normal'}, {'diagonistic_id': 'D002', 'patient_id': 'P002', 'test': 'X-Ray', 'result': 'Fracture'}, {'diagonistic_id': 'D003', 'patient_id': 'P003', 'test': 'MRI', 'result': 'Normal'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Transform Data**\n",
        "\n",
        "**2.1. Clean the Diagnostic Data**\n",
        "\n",
        "\n",
        "Clean patient data: Letâ€™s assume you need to filter out patients who are younger than 40\n",
        "years old for a specific study.\n",
        "\n"
      ],
      "metadata": {
        "id": "QARgvzg4Gaem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out patients who are younger than 40 years old\n",
        "filtered_patients_df = patients_df[patients_df['age'] >= 40]\n",
        "\n",
        "# Display the cleaned data\n",
        "print(\"Filtered Patients Data (Age >= 40):\")\n",
        "print(filtered_patients_df)\n",
        "\n",
        "# Save the cleaned data to a new CSV file\n",
        "filtered_patients_df.to_csv('/content/filtered_patients.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPQrKmOTGf8M",
        "outputId": "68c40035-64af-4985-939f-751c49812fb4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Patients Data (Age >= 40):\n",
            "    patient_id               name  age  gender\n",
            "0         P001        James Smith   45    Male\n",
            "2         P003    Robert Williams   56    Male\n",
            "4         P005         John Jones   67    Male\n",
            "5         P006       Linda Garcia   40  Female\n",
            "7         P008      Barbara Davis   55  Female\n",
            "..         ...                ...  ...     ...\n",
            "193       P194  Dorothy Patterson   48  Female\n",
            "194       P195      Benjamin Ward   55    Male\n",
            "195       P196       Emily Brooks   41  Female\n",
            "197       P198         Judith Lee   50  Female\n",
            "199       P200    Rebecca Sanders   57  Female\n",
            "\n",
            "[127 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2. Enrich the Diagnostic Data**\n",
        "\n",
        "\n",
        "Enrich diagnostic data with patient information: Join the diagnostics data with\n",
        "patient details (name, age, gender) to provide context for the test results.\n"
      ],
      "metadata": {
        "id": "XWTlr7q-GiMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diagonistic_df = pd.DataFrame(diagonistic_data)\n",
        "\n",
        "# Join the diagnostic data with the filtered patient details\n",
        "enriched_df = pd.merge(diagonistic_df, filtered_patients_df, on=\"patient_id\")\n",
        "\n",
        "# Display the enriched DataFrame\n",
        "print(\"Enriched Diagonistics Data:\")\n",
        "print(enriched_df)\n",
        "\n",
        "# Save the enriched DataFrame to a new CSV file\n",
        "enriched_df.to_csv('/content/enriched_diagonistics.csv', index=False)\n",
        "print(\"enriched_diagnostics.csv file has been created.\")\n"
      ],
      "metadata": {
        "id": "-AE458wsGniG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e296998d-c173-4902-eec4-745cdabb0504"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enriched Diagonistics Data:\n",
            "  diagonistic_id patient_id        test  result             name  age gender\n",
            "0           D001       P001  Blood Test  Normal      James Smith   45   Male\n",
            "1           D003       P003         MRI  Normal  Robert Williams   56   Male\n",
            "enriched_diagnostics.csv file has been created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Load Data into MongoDB**\n",
        "\n",
        "Now that the data is transformed and cleaned, load the product and sales data into MongoDB.\n",
        "\n",
        "**3.1. Connect to MongoDB**\n",
        "\n",
        "Ensure you have MongoDB running locally or use MongoDB Atlas. Connect to MongoDB using PyMongo."
      ],
      "metadata": {
        "id": "N_J9biezGzQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo\n",
        "!pip install --upgrade pymongo\n",
        "\n",
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "uri = \"mongodb+srv://tsjannoun123:KufyyNNqnno0atX9@cluster0.sb8py.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "# Create a new client and connect to the server\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "# Send a ping to confirm a successful connection\n",
        "try:\n",
        "    client.admin.command('ping')\n",
        "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Access a specific database\n",
        "db = client['patients_db']\n",
        "\n"
      ],
      "metadata": {
        "id": "J-WpayvQG3NP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a718ea-6cab-4b26-ae47-dc81143e5401"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.11)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.11)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
            "Pinged your deployment. You successfully connected to MongoDB!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2. Load Patients Data**\n",
        "\n",
        "Insert the transformed patients data into the MongoDB patients collection."
      ],
      "metadata": {
        "id": "KdbvO_ynG5W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrame to dictionary and insert into MongoDB\n",
        "patients_records = filtered_patients_df.to_dict(orient='records')\n",
        "# Changed orient to 'records' as 'patients' is not a valid option\n",
        "db.patients.insert_many(patients_records)\n",
        "print(\"Loaded Patients Data into MongoDB\")"
      ],
      "metadata": {
        "id": "yFPviZ0jG-hM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8ea603-3f57-4a3f-fc70-bbd9afdce05f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Patients Data into MongoDB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3. Load Diagonistic Data**\n",
        "\n",
        "Insert the enriched diagonistic data into the MongoDB sales collection."
      ],
      "metadata": {
        "id": "RcPF_GfEHBcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrame to dictionary and insert into MongoDB\n",
        "# diagnostic_data = sales_df.to_dict(orient='records') # sales_df is not defined, using enriched_df instead\n",
        "diagnostic_data = enriched_df.to_dict(orient='records')  # enriched_df holds the diagnostic data\n",
        "db.diagnostics.insert_many(diagnostic_data)\n",
        "print(\"Loaded Diagnostics Data into MongoDB\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xGqJWM2sHHSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb74daf-16b4-4340-8401-d8ffb69fce03"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Diagnostics Data into MongoDB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Automate the ETL Process**\n",
        "\n",
        "To make the ETL process reusable, wrap the steps into functions and run the ETL pipeline from start to finish."
      ],
      "metadata": {
        "id": "0w-Iu3KuHKGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract patient data from CSV\n",
        "def extract_patients():\n",
        "    return pd.read_csv('/content/filtered_patients.csv')\n",
        "\n",
        "# Function to extract diagnostic data\n",
        "def extract_diagnostics():\n",
        "    diagnostic_data = [\n",
        "        {\"diagnostic_id\": \"D001\", \"patient_id\": \"P001\", \"test\": \"Blood Test\", \"result\": \"Normal\"},\n",
        "        {\"diagnostic_id\": \"D002\", \"patient_id\": \"P002\", \"test\": \"X-Ray\", \"result\": \"Fracture\"},\n",
        "        {\"diagnostic_id\": \"D003\", \"patient_id\": \"P003\", \"test\": \"MRI\", \"result\": \"Normal\"}\n",
        "    ]\n",
        "    return pd.DataFrame(diagnostic_data)\n",
        "\n",
        "# Function to transform patient data\n",
        "def transform_patients(patients_df):\n",
        "    # Filter patients who are 40 years old or older\n",
        "    patients_df['age'] = pd.to_numeric(patients_df['age'], errors='coerce')\n",
        "    return patients_df[patients_df['age'] >= 40]\n",
        "\n",
        "# Function to transform diagnostic data\n",
        "def transform_diagnostics(diagnostic_df, patients_df):\n",
        "    return pd.merge(diagnostic_df, patients_df[['patient_id', 'name', 'age', 'gender']], on='patient_id', how='left')\n",
        "\n",
        "# Function to load data into MongoDB\n",
        "def load_data(patients_df, diagnostic_df, connection_string, database_name):\n",
        "    client = MongoClient(connection_string)\n",
        "    db = client[database_name]\n",
        "    # Convert DataFrame to dictionary and insert into MongoDB\n",
        "    patients_records = patients_df.to_dict(orient='records')\n",
        "    db.patients.insert_many(patients_records)\n",
        "    print(\"Loaded Patients Data into MongoDB\")\n",
        "\n",
        "    diagnostics_records = diagnostic_df.to_dict(orient='records')\n",
        "    db.diagnostics.insert_many(diagnostics_records)\n",
        "    print(\"Loaded Diagnostics Data into MongoDB\")\n",
        "\n",
        "# Complete ETL pipeline\n",
        "def run_etl(patients_file, diagnostics_file, connection_string, database_name):\n",
        "    patients_df = extract_patients()\n",
        "    diagnostic_df = extract_diagnostics()\n",
        "    transformed_patients_df = transform_patients(patients_df)\n",
        "    transformed_diagnostics_df = transform_diagnostics(diagnostic_df, transformed_patients_df)\n",
        "    load_data(transformed_patients_df, transformed_diagnostics_df, connection_string, database_name)\n",
        "\n",
        "# Parameters\n",
        "patients_file = '/content/filtered_patients.csv'\n",
        "diagnostics_file = '/content/diagnostics.csv'\n",
        "connection_string = \"mongodb+srv://tsjannoun123:KufyyNNqnno0atX9@cluster0.sb8py.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "database_name = \"patients_db\"\n",
        "\n",
        "# Run the ETL pipeline\n",
        "run_etl(patients_file, diagnostics_file, connection_string, database_name)\n",
        "print(\"ETL Process Completed!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "p-h6IeqiHRIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c64ca3c-ca37-485f-9d9f-51f3384bada9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Patients Data into MongoDB\n",
            "Loaded Diagnostics Data into MongoDB\n",
            "ETL Process Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**\n",
        "This hands-on lab provides a comprehensive introduction to the ETL process, from extracting raw data from multiple sources, transforming it for quality and consistency, and finally loading it into MongoDB."
      ],
      "metadata": {
        "id": "IJ2xNTfeEjAk"
      }
    }
  ]
}