{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saerarawas/AAI_634O_A11_202520/blob/main/week3/Implementing_ETL_Using_Python_for_a_Healthcare_Application_Implementing_the_ETL_Process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hands-on Lab: Implementing the ETL (Extract, Transform, Load) Process**"
      ],
      "metadata": {
        "id": "MwRtqhfoEmJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "\n",
        "In this hands-on lab, students will learn how to implement the fundamental steps of the ETL process by extracting data from multiple sources, transforming the data, and loading it into a database. Students will use Python along with libraries such as Pandas for data transformation and PyMongo for loading the data into a MongoDB database.\n",
        "\n",
        "By the end of this lab, students will be able to:\n",
        "\n",
        "* Extract data from different sources (CSV and API).\n",
        "* Clean, transform, and validate the data.\n",
        "* Load the transformed data into MongoDB.\n",
        "* Automate the ETL process by building a reusable pipeline."
      ],
      "metadata": {
        "id": "_flGWYZjEygA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-requisites:**\n",
        "\n",
        "* Basic knowledge of Python.\n",
        "* MongoDB Atlas account (or a local MongoDB instance).\n",
        "* Install the required Python libraries:\n",
        "\n"
      ],
      "metadata": {
        "id": "WNqvAT4rFKjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this Lab:**\n",
        "\n",
        "You are tasked with creating an ETL pipeline for a fictitious retail company. You will extract product and sales data from different sources (a CSV file and a REST API), transform the data by cleaning and standardizing it, and load the transformed data into MongoDB for further analysis."
      ],
      "metadata": {
        "id": "Af48YJb-FwIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1WdYTTnaUyKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Python and Pandas to extract the product data from this CSV file."
      ],
      "metadata": {
        "id": "3C7Wvw-WGM9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Extract Data**\n",
        "**Patient data (CSV file):**\n",
        "You have a CSV file named patients.csv that contains basic patient information, such as ID,\n",
        "name, age, and gender.\n"
      ],
      "metadata": {
        "id": "8GXpeEGiUwRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file from the content folder\n",
        "patients_df = pd.read_csv('/content/patients.csv')\n",
        "print(\"Extracted Patients Data:\")\n",
        "print(patients_df)\n",
        "# Print length of DataFrame\n",
        "file_length = len(patients_df)\n",
        "print(f\"Total Patients: {file_length}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ8CgWCLUYaO",
        "outputId": "c9e56cab-bb14-4430-8f94-6031e4d56231"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Patients Data:\n",
            "    patient_id             name  age  gender\n",
            "0         P001      James Smith   45    Male\n",
            "1         P002     Mary Johnson   32  Female\n",
            "2         P003  Robert Williams   56    Male\n",
            "3         P004   Patricia Brown   29  Female\n",
            "4         P005       John Jones   67    Male\n",
            "..         ...              ...  ...     ...\n",
            "195       P196     Emily Brooks   41  Female\n",
            "196       P197      Jack Fisher   29    Male\n",
            "197       P198       Judith Lee   50  Female\n",
            "198       P199       Sean Kelly   38    Male\n",
            "199       P200  Rebecca Sanders   57  Female\n",
            "\n",
            "[200 rows x 4 columns]\n",
            "Total Patients: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diagnostics data (simulated API):**\n",
        "\n",
        "Diagnostics data is retrieved from a simulated API that provides information about medical\n",
        "tests and results."
      ],
      "metadata": {
        "id": "ftylwwhwGRT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Simulated API response (in a real scenario, use requests.get(URL).json())\n",
        "diagnostic_data = [\n",
        "    {\"diagnostic_id\": \"D001\", \"patient_id\": \"P001\", \"test\": \"Blood Test\", \"result\": \"Normal\"},\n",
        "    {\"diagnostic_id\": \"D002\", \"patient_id\": \"P002\", \"test\": \"X-Ray\", \"result\": \"Fracture\"},\n",
        "    {\"diagnostic_id\": \"D003\", \"patient_id\": \"P003\", \"test\": \"MRI\", \"result\": \"Normal\"}\n",
        "]\n",
        "\n",
        "print(\"Extracted Diagnostic Data:\")\n",
        "print(diagnostic_data)\n",
        "# Print length of DataFrame\n",
        "file_length = len(diagnostic_data)\n",
        "print(f\"Diagnostic Data: {file_length}\")"
      ],
      "metadata": {
        "id": "mcwhIOGxGXok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a156f6-fed4-4eef-937f-da565f9a9f42"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Diagnostic Data:\n",
            "[{'diagnostic_id': 'D001', 'patient_id': 'P001', 'test': 'Blood Test', 'result': 'Normal'}, {'diagnostic_id': 'D002', 'patient_id': 'P002', 'test': 'X-Ray', 'result': 'Fracture'}, {'diagnostic_id': 'D003', 'patient_id': 'P003', 'test': 'MRI', 'result': 'Normal'}]\n",
            "Diagnostic Data: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Transform Data**\n",
        "\n",
        "**2.1. Clean the Diagnostic Data**\n",
        "\n",
        "\n",
        "Clean patient data: Letâ€™s assume you need to filter out patients who are younger than 40\n",
        "years old for a specific study.\n",
        "\n"
      ],
      "metadata": {
        "id": "QARgvzg4Gaem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out patients who are younger than 40 years old\n",
        "filtered_patients_df = patients_df[patients_df['age'] > 40]\n",
        "\n",
        "# Display the cleaned data\n",
        "print(\"Filtered Patients Data (Age >= 40):\")\n",
        "print(filtered_patients_df)\n",
        "\n",
        "# Save the cleaned data to a new CSV file\n",
        "filtered_patients_df.to_csv('/content/filtered_patients.csv', index=False)\n",
        "# Print length of DataFrame\n",
        "file_length = len(filtered_patients_df)\n",
        "print(f\"Patients younger than 40: {file_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPQrKmOTGf8M",
        "outputId": "1f50edd1-de4a-46ad-c5e5-f7ef225dbde3"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Patients Data (Age >= 40):\n",
            "    patient_id                name  age  gender\n",
            "0         P001         James Smith   45    Male\n",
            "2         P003     Robert Williams   56    Male\n",
            "4         P005          John Jones   67    Male\n",
            "7         P008       Barbara Davis   55  Female\n",
            "9         P010  Elizabeth Martinez   62  Female\n",
            "..         ...                 ...  ...     ...\n",
            "193       P194   Dorothy Patterson   48  Female\n",
            "194       P195       Benjamin Ward   55    Male\n",
            "195       P196        Emily Brooks   41  Female\n",
            "197       P198          Judith Lee   50  Female\n",
            "199       P200     Rebecca Sanders   57  Female\n",
            "\n",
            "[120 rows x 4 columns]\n",
            "Patients younger than 40: 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2. Enrich the Diagnostic Data**\n",
        "\n",
        "\n",
        "Enrich diagnostic data with patient information: Join the diagnostics data with\n",
        "patient details (name, age, gender) to provide context for the test results.\n"
      ],
      "metadata": {
        "id": "XWTlr7q-GiMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert diagnostics_data to a DataFrame\n",
        "diagnostics_df = pd.DataFrame(diagnostic_data)\n",
        "\n",
        "#join diagnostics data with patient data to add patient name age and gender\n",
        "diagnostics_df = pd.merge(diagnostics_df, patients_df[['patient_id', 'name', 'age', 'gender']], on='patient_id', how='left')\n",
        "print(\"Enriched Diagnostics Data:\")\n",
        "print(diagnostics_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwqkb46rgg__",
        "outputId": "92413d87-54fc-473d-93e6-35865bf74f47"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enriched Diagnostics Data:\n",
            "  diagnostic_id patient_id        test    result             name  age  gender\n",
            "0          D001       P001  Blood Test    Normal      James Smith   45    Male\n",
            "1          D002       P002       X-Ray  Fracture     Mary Johnson   32  Female\n",
            "2          D003       P003         MRI    Normal  Robert Williams   56    Male\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Load Data into MongoDB**\n",
        "\n",
        "Now that the data is transformed and cleaned, load the product and sales data into MongoDB.\n",
        "\n",
        "**3.1. Connect to MongoDB**\n",
        "\n",
        "Ensure you have MongoDB running locally or use MongoDB Atlas. Connect to MongoDB using PyMongo."
      ],
      "metadata": {
        "id": "N_J9biezGzQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo\n",
        "!pip install --upgrade pymongo\n",
        "\n",
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "uri = \"mongodb+srv://tsjannoun123:KufyyNNqnno0atX9@cluster0.sb8py.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "# Create a new client and connect to the server\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "# Send a ping to confirm a successful connection\n",
        "try:\n",
        "    client.admin.command('ping')\n",
        "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Access a specific database\n",
        "db = client['patients_healthcare_db']\n",
        "\n"
      ],
      "metadata": {
        "id": "J-WpayvQG3NP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb6ba8d-a429-49f5-96cf-b5b65ee97ad4"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.11)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.11)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
            "Pinged your deployment. You successfully connected to MongoDB!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2. Load Patients Data**\n",
        "\n",
        "Insert the transformed patients data into the MongoDB patients collection."
      ],
      "metadata": {
        "id": "KdbvO_ynG5W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrame to dictionary and insert into MongoDB\n",
        "patients_records = filtered_patients_df.to_dict(orient='records')\n",
        "# Changed orient to 'records' as 'patients' is not a valid option\n",
        "db.patients.insert_many(patients_records)\n",
        "print(\"Loaded Patients Data into MongoDB\")\n",
        "# Print the number of records\n",
        "record_count = db.patients.count_documents({})\n",
        "print(f\"Number of records loaded: {record_count}\")"
      ],
      "metadata": {
        "id": "yFPviZ0jG-hM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2a96f8-9cc9-40cf-9a91-9a9f7d06d5a3"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Patients Data into MongoDB\n",
            "Number of records loaded: 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3. Load Diagonistic Data**\n",
        "\n",
        "Insert the diagonistic data into the MongoDB collection."
      ],
      "metadata": {
        "id": "RcPF_GfEHBcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrame to dictionary and insert into MongoDB\n",
        "diagnostics_records = diagnostics_df.to_dict(orient='records')\n",
        "insert_result1 = db.diagnostics.insert_many(diagnostics_records)\n",
        "if insert_result1.acknowledged:\n",
        "  print(f\"{len(insert_result1.inserted_ids)} Record of diagnostics data loaded into MongoDB\")\n",
        "else:\n",
        "  print(\"Error loading diagnostics data into MongoDB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZw5T1xRh6PP",
        "outputId": "b9a0bfc0-1277-4a41-8eaf-4507cc06878c"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 Record of diagnostics data loaded into MongoDB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Automate the ETL Process**\n",
        "\n",
        "To make the ETL process reusable, wrap the steps into functions and run the ETL pipeline from start to finish."
      ],
      "metadata": {
        "id": "0w-Iu3KuHKGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_patients():\n",
        "    return pd.read_csv('/content/filtered_patients.csv')\n",
        "\n",
        "def extract_diagnostics():\n",
        "    return pd.DataFrame(diagnostic_data)\n",
        "\n",
        "def transform_patients(patients_df):\n",
        "    return patients_df[patients_df['age'] > 40]\n",
        "\n",
        "def transform_diagnostics(diagnostics_df, patients_df):\n",
        "    return pd.merge(diagnostics_df, patients_df[['patient_id', 'name', 'age', 'gender']], on='patient_id', how='left')\n",
        "\n",
        "def load_data(patients_df, diagnostics_df):\n",
        "    db.patients_ETL.insert_many(patients_df.to_dict(orient='records'))\n",
        "    db.diagnostics_ETL.insert_many(diagnostics_df.to_dict(orient='records'))\n",
        "\n",
        "# Run the ETL pipeline\n",
        "patients_df = extract_patients()\n",
        "diagnostics_df = extract_diagnostics()\n",
        "transformed_patients_df = transform_patients(patients_df)\n",
        "transformed_diagnostics_df = transform_diagnostics(diagnostics_df, patients_df)\n",
        "load_data(transformed_patients_df, transformed_diagnostics_df)\n",
        "print(\"ETL Process Completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-4wLdoibMCe",
        "outputId": "09243e08-1714-4280-a09a-1a00ded46c25"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ETL Process Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**\n",
        "This hands-on lab provides a comprehensive introduction to the ETL process, from extracting raw data from multiple sources, transforming it for quality and consistency, and finally loading it into MongoDB."
      ],
      "metadata": {
        "id": "IJ2xNTfeEjAk"
      }
    }
  ]
}