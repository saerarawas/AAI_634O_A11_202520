{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoJfWlszNNx/Ggc9YwrcBy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saerarawas/AAI_634O_A11_202520/blob/main/week2/Sales_Mongodb_dash_Rawas_Saera.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the number of records\n",
        "num_records = 1000\n",
        "\n",
        "# Generate random dates within a specific range\n",
        "dates = pd.date_range(start='2023-01-01', end='2023-12-31', periods=num_records)\n",
        "\n",
        "# Generate product IDs (e.g., P001, P002, ..., P1000)\n",
        "product_ids = [f'P{str(i).zfill(3)}' for i in range(1, num_records + 1)]\n",
        "\n",
        "# Generate random sales amounts\n",
        "sales_amounts = np.random.randint(100, 1000, size=num_records)\n",
        "\n",
        "# Define a list of city locations in the USA\n",
        "city_locations = [\n",
        "    'New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'Philadelphia',\n",
        "    'San Antonio', 'San Diego', 'Dallas', 'San Jose', 'Austin', 'Jacksonville',\n",
        "    'Fort Worth', 'Columbus', 'Charlotte', 'San Francisco', 'Indianapolis', 'Seattle',\n",
        "    'Denver', 'Washington', 'Boston', 'El Paso', 'Nashville', 'Detroit', 'Oklahoma City',\n",
        "    'Portland', 'Las Vegas', 'Memphis', 'Louisville', 'Baltimore', 'Milwaukee',\n",
        "    'Albuquerque', 'Tucson', 'Fresno', 'Sacramento', 'Kansas City', 'Long Beach',\n",
        "    'Mesa', 'Atlanta', 'Colorado Springs', 'Virginia Beach', 'Raleigh', 'Omaha',\n",
        "    'Miami', 'Oakland', 'Minneapolis', 'Tulsa', 'Arlington', 'New Orleans'\n",
        "]\n",
        "\n",
        "# Randomly assign city locations to the records\n",
        "locations = np.random.choice(city_locations, size=num_records)\n",
        "\n",
        "# Create a DataFrame with the generated data\n",
        "data = {\n",
        "    'date': dates,\n",
        "    'product_id': product_ids,\n",
        "    'sales_amount': sales_amounts,\n",
        "    'store_location': locations\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('sales_data.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Print the length of the DataFrame\n",
        "print(f\"Length of the DataFrame: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huRK264WDJrw",
        "outputId": "b63e9d95-f52e-4c5c-cae0-d8d56fc73ae8"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           date product_id  sales_amount store_location\n",
            "0 2023-01-01 00:00:00.000000000       P001           131          Omaha\n",
            "1 2023-01-01 08:44:41.081081081       P002           574          Tulsa\n",
            "2 2023-01-01 17:29:22.162162162       P003           225        Phoenix\n",
            "3 2023-01-02 02:14:03.243243243       P004           846    San Antonio\n",
            "4 2023-01-02 10:58:44.324324324       P005           604       San Jose\n",
            "Length of the DataFrame: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo\n",
        "!pip install --upgrade pymongo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRtAWkXSDa0P",
        "outputId": "ea25888f-1bda-45e2-f39b-8cfa164c758e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.11)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.11)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "# Connect to MongoDB (update the connection string if needed)\n",
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "uri = \"mongodb+srv://tsjannoun123:KufyyNNqnno0atX9@cluster0.sb8py.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "# Create a new client and connect to the server\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "# Send a ping to confirm a successful connection\n",
        "try:\n",
        "    client.admin.command('ping')\n",
        "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "db = client['sales_db']\n",
        "sales_collection = db['sales']\n",
        "\n",
        "# Convert the DataFrame to a list of dictionaries and insert into MongoDB\n",
        "# Use 'df' instead of 'sales_data' to access the DataFrame\n",
        "sales_records = df.to_dict('records')\n",
        "sales_collection.insert_many(sales_records)\n",
        "\n",
        "print('Sales data inserted into MongoDB.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1JBjwKLCiP4",
        "outputId": "ca4c4f99-409b-449d-b7d1-1154c89dab22"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinged your deployment. You successfully connected to MongoDB!\n",
            "Sales data inserted into MongoDB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "additional_records = [\n",
        "    {\"store\": \"Store A\", \"product\": \"Product X\", \"date\": \"2025-02-01\", \"sales\": 100},\n",
        "    {\"store\": \"Store B\", \"product\": \"Product Y\", \"date\": \"2025-02-02\", \"sales\": 150}\n",
        "]\n",
        "sales_collection.insert_many(additional_records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tPW68RsCs24",
        "outputId": "25282c6c-c789-444d-860a-43e151714920"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InsertManyResult([ObjectId('67a05e6af4e0d9a98c9e3933'), ObjectId('67a05e6af4e0d9a98c9e3934')], acknowledged=True)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = {\"store\": \"Store A\"}\n",
        "results = sales_collection.find(query)\n",
        "\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL0fKVxrCvtl",
        "outputId": "da8d6599-d53c-4ef5-be86-380c3887465a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_id': ObjectId('67a05e6af4e0d9a98c9e3933'), 'store': 'Store A', 'product': 'Product X', 'date': '2025-02-01', 'sales': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filter_query = {\"product\": \"Product X\"}\n",
        "update_query = {\"$set\": {\"sales\": 200}}\n",
        "\n",
        "sales_collection.update_many(filter_query, update_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LADSU0cGCyTb",
        "outputId": "308fe117-942e-44ea-96a3-f283d0945879"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UpdateResult({'n': 1, 'electionId': ObjectId('7fffffff000000000000000d'), 'opTime': {'ts': Timestamp(1738563178, 5), 't': 13}, 'nModified': 1, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1738563178, 5), 'signature': {'hash': b'O0\\x001\\xc5\\x9f\\xb0\\xd3If\\xf1D\\x14\\xa9v\\xdb\\xba\\xe2\\x8e\\xfb', 'keyId': 7418578331844476933}}, 'operationTime': Timestamp(1738563178, 5), 'updatedExisting': True}, acknowledged=True)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "delete_query = {\"date\": {\"$lt\": \"2024-01-01\"}}\n",
        "sales_collection.delete_many(delete_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDWdo1zsC3om",
        "outputId": "bf4a12f4-ae00-4736-acdb-ba99fe7ea726"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeleteResult({'n': 0, 'electionId': ObjectId('7fffffff000000000000000d'), 'opTime': {'ts': Timestamp(1738563178, 5), 't': 13}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1738563178, 5), 'signature': {'hash': b'O0\\x001\\xc5\\x9f\\xb0\\xd3If\\xf1D\\x14\\xa9v\\xdb\\xba\\xe2\\x8e\\xfb', 'keyId': 7418578331844476933}}, 'operationTime': Timestamp(1738563178, 5)}, acknowledged=True)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade plotly dash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyXWy-ZRC5qv",
        "outputId": "49362852-6c82-4023-c8ed-4cb7b97ddcdf"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (6.0.0)\n",
            "Requirement already satisfied: dash in /usr/local/lib/python3.11/dist-packages (2.18.2)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from plotly) (1.24.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from dash) (3.0.3)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.11/dist-packages (from dash) (3.0.6)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.11/dist-packages (from dash) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.11/dist-packages (from dash) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash) (5.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash) (8.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dash) (2.32.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dash) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash) (75.1.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Werkzeug<3.1->dash) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from retrying->dash) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import dash\n",
        "from dash import dcc, html\n",
        "from dash.dependencies import Input, Output\n",
        "import plotly.express as px\n",
        "from pymongo import MongoClient\n",
        "import pandas as pd\n",
        "\n",
        "# Connect to MongoDB\n",
        "uri = \"mongodb+srv://tsjannoun123:KufyyNNqnno0atX9@cluster0.sb8py.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "client = MongoClient(uri)\n",
        "db = client['sales_db']\n",
        "collection = db['sales']\n",
        "\n",
        "# Fetch sales data from MongoDB\n",
        "sales_data = pd.DataFrame(list(collection.find()))\n",
        "\n",
        "# Ensure the data has the expected columns\n",
        "expected_columns = ['date', 'product_id', 'sales_amount', 'store_location']\n",
        "if not all(column in sales_data.columns for column in expected_columns):\n",
        "    raise ValueError(\"Data is missing expected columns. Please check your MongoDB data.\")\n",
        "\n",
        "# Aggregate sales data by store location\n",
        "sales_by_location = sales_data.groupby('store_location')['sales_amount'].sum().reset_index()\n",
        "\n",
        "# Initialize the Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "# Create a bar chart\n",
        "fig = px.bar(sales_by_location, x='store_location', y='sales_amount', title='Sales by Store Location')\n",
        "\n",
        "# Set up the layout of the app\n",
        "app.layout = html.Div(children=[\n",
        "    html.H1(children='Sales Dashboard'),\n",
        "    dcc.Graph(id='sales-bar-chart', figure=fig)\n",
        "])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run_server(debug=True, port=8051)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "1arNFaqOEVIa",
        "outputId": "641faef4-c522-4664-e292-ebea2aa08cda"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8051, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Changes Made to the MongoDB Database**\n",
        "\n",
        "**Insertion of Initial Sales Data:**\n",
        "\n",
        "**Action:** Inserted sales records into the MongoDB collection.\n",
        "\n",
        "\n",
        "**Details:** Generated a DataFrame with random sales data, which included fields such as date, product ID, sales amount, and store location. The data was then inserted into the MongoDB collection using the insert_many method.\n",
        "\n",
        "\n",
        "**Reason:** This operation was necessary to populate the database with initial sales data for subsequent analysis and visualization.\n"
      ],
      "metadata": {
        "id": "uNkvk4VQHniW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insertion of Additional Sales Records:**\n",
        "\n",
        "**Action**: Inserted additional sales records into the MongoDB collection.\n",
        "\n",
        "\n",
        "**Details:** Two new sales records were added to the collection with details like store, date, product, and amount.\n",
        "\n",
        "\n",
        "**Reason:** This operation added new data to the collection, simulating the addition of new sales transactions.\n"
      ],
      "metadata": {
        "id": "yU350CCsH1PE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Querying Sales Data:**\n",
        "\n",
        "**Action**: Queried sales data by store, date, and product.\n",
        "\n",
        "\n",
        "**Details:** Used the find method to retrieve sales records based on specific criteria such as store location, date, and product.\n",
        "\n",
        "\n",
        "**Reason :** This operation was performed to analyze and extract specific subsets of data for further processing or reporting."
      ],
      "metadata": {
        "id": "vkjTm9PgH5WP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Updating Sales Records:**\n",
        "\n",
        "**Action:** Updated sales amounts for a specific product.\n",
        "\n",
        "\n",
        "**Details:** Used the update_many method to increase the sales amount by 50 for the product \"Product X\".\n",
        "\n",
        "\n",
        "**Reason:** This operation was necessary to adjust the sales data for the product, simulating a correction or update to the sales records.\n"
      ],
      "metadata": {
        "id": "ETawclkxIJQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deleting Outdated Sales Records:**\n",
        "\n",
        "**Action:** Deleted sales records with dates earlier than 2024-01-01.\n",
        "\n",
        "\n",
        "**Details:** Used the delete_many method to remove outdated sales records from the collection.\n",
        "\n",
        "\n",
        "**Reason:**  This operation cleaned up old data from the database, ensuring that the collection only contains relevant and current sales records.\n"
      ],
      "metadata": {
        "id": "M99frvqFIc5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**CRUD** stands for Create, Read, Update, and Delete. These are the four basic operations required to manage and manipulate data in a database. **Create**: Allows for adding new records to the database. This is crucial for continuously collecting new data. **Read**: Enables the retrieval of data from the database. This is necessary for analyzing and reporting the data. **Update**: Provides a way to modify existing records in the database. This is important for correcting errors and keeping data current. **Delete**: Allows for removing records from the database. This is necessary for cleaning up outdated or irrelevant data.\n",
        "\n",
        "\n",
        "CRUD operations are fundamental for effective database management, as they ensure that the data remains accurate, current, and relevant.\n"
      ],
      "metadata": {
        "id": "uNjLR5ksJoH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L_qFnEW3J5IF"
      }
    }
  ]
}